AS AN ASYNCHRONOUS EVENT-DRIVEN JAVASCRIPT RUNTIME, NODE.JS IS DESIGNED TO BUILD SCALABLE NETWORK APPLICATIONS. IN THE FOLLOWING "HELLO WORLD" EXAMPLE, MANY CONNECTIONS CAN BE HANDLED CONCURRENTLY. UPON EACH CONNECTION, THE CALLBACK IS FIRED, BUT IF THERE IS NO WORK TO BE DONE, NODE.JS WILL SLEEP. THIS IS IN CONTRAST TO TODAY'S MORE COMMON CONCURRENCY MODEL, IN WHICH OS THREADS ARE EMPLOYED. THREAD-BASED NETWORKING IS RELATIVELY INEFFICIENT AND VERY DIFFICULT TO USE. FURTHERMORE, USERS OF NODE.JS ARE FREE FROM WORRIES OF DEAD-LOCKING THE PROCESS, SINCE THERE ARE NO LOCKS. ALMOST NO FUNCTION IN NODE.JS DIRECTLY PERFORMS I/O, SO THE PROCESS NEVER BLOCKS. BECAUSE NOTHING BLOCKS, SCALABLE SYSTEMS ARE VERY REASONABLE TO DEVELOP IN NODE.JS.
IF SOME OF THIS LANGUAGE IS UNFAMILIAR, THERE IS A FULL ARTICLE ON BLOCKING VS. NON-BLOCKING. NODE.JS IS SIMILAR IN DESIGN TO, AND INFLUENCED BY, SYSTEMS LIKE RUBY'S EVENT MACHINE AND PYTHON'S TWISTED. NODE.JS TAKES THE EVENT MODEL A BIT FURTHER. IT PRESENTS AN EVENT LOOP AS A RUNTIME CONSTRUCT INSTEAD OF AS A LIBRARY. IN OTHER SYSTEMS, THERE IS ALWAYS A BLOCKING CALL TO START THE EVENT-LOOP. TYPICALLY, BEHAVIOR IS DEFINED THROUGH CALLBACKS AT THE BEGINNING OF A SCRIPT, AND AT THE END A SERVER IS STARTED THROUGH A BLOCKING CALL LIKE EVENTMACHINE::RUN(). IN NODE.JS, THERE IS NO SUCH START-THE-EVENT-LOOP CALL. NODE.JS SIMPLY ENTERS THE EVENT LOOP AFTER EXECUTING THE INPUT SCRIPT. NODE.JS EXITS THE EVENT LOOP WHEN THERE ARE NO MORE CALLBACKS TO PERFORM. THIS BEHAVIOR IS LIKE BROWSER JAVASCRIPT — THE EVENT LOOP IS HIDDEN FROM THE USER.
HTTP IS A FIRST-CLASS CITIZEN IN NODE.JS, DESIGNED WITH STREAMING AND LOW LATENCY IN MIND. THIS MAKES NODE.JS WELL SUITED FOR THE FOUNDATION OF A WEB LIBRARY OR FRAMEWORK.
NODE.JS BEING DESIGNED WITHOUT THREADS DOESN'T MEAN YOU CAN'T TAKE ADVANTAGE OF MULTIPLE CORES IN YOUR ENVIRONMENT. CHILD PROCESSES CAN BE SPAWNED BY USING OUR CHILD_PROCESS.FORK() API, AND ARE DESIGNED TO BE EASY TO COMMUNICATE WITH. BUILT UPON THAT SAME INTERFACE IS THE CLUSTER MODULE, WHICH ALLOWS YOU TO SHARE SOCKETS BETWEEN PROCESSES TO ENABLE LOAD BALANCING OVER YOUR CORES.